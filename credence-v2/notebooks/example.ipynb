{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f64849",
   "metadata": {},
   "source": [
    "# **Credence** - Evaluating Causal Inference Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a3390",
   "metadata": {},
   "source": [
    "*Premise*: Retrospective causal inference methods are widely used to estimate the impact of an intervention where randomized controlled trials are not an option for example, fee changes or marketing campaigns. The main challenge in retrospective and non-experimental causal inference is that we only observe the outcome under one of the treatment choices while the counterfactual is never observed. Causal inference methods aims to re-create the scenario in which the alternative treatment was chosen i.e. estimating the counterfactual. \n",
    "\n",
    "*Background*: Traditional causal inference methods are primarily evaluated quantitatively in two ways: 1) placebo tests and 2) tests on simulated data. Placebo tests check that the treatment effect estimated by a particular method is zero during a period there is actually no intervention: in that situation, the actual should match the counterfactual. Testing on simulated data is limited because the data generative process is often simple and lacks the complexities of real world datasets where the method is actually applied. For applied researchers, the important question is understanding how well a method actually performs in realistic situations. \n",
    "\n",
    "*Contribution*: In this work, we propose a framework for learning the generative mechanism that generates complex and realistic samples with known treatment effects. The framework uses a black-box generator like VAE or GAN coupled with an interpretable part. The black-box model allows generation of complex data while the interpretable model allows manipulation and intervention on the samples to encode treatment effects. The generated data can be used to assess the performance of (multiple) causal estimation method(s). The performance metrics (e.g. accuracy or error-rates) are then used to choose the most appropriate causal estimation methods for a given dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab61d0c",
   "metadata": {},
   "source": [
    "## Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c916a666",
   "metadata": {},
   "source": [
    "![Credence Framework](../images/credenceframework.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe787cb0",
   "metadata": {},
   "source": [
    "Credence uses state-of-the-art deep generative models such as variational auto-encoders (VAEs) to approximate the universe of complex datasets. These generative models are trained and validated on a collection of observed data sets. Credence uses these trained deep generative models to generate data that has analogous complexity to the observed data. Credenceâ€™s procedure enables users to have perfect knowledge about  ground truth treatment effects of the intervention in the generated data. This allows the users to evaluate their method in a principled fashion without compromising on the complexity or the realness of the data they are evaluating the method on.\n",
    "\n",
    "Credence learns a generative model by anchoring the level of endogeneity or treatment effect or anchoring both simultaneously. Anchoring the treatment effect and/or endogeneity is analogous to constraining the search space of potential data generators. Our approach can be conceptualized as projecting the true data-generative process to a constrained space of data-generators and finding the closest data-generator that conserves the joint distribution of X,Y,Z as close as possible to that of the observed data under the constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d242a",
   "metadata": {},
   "source": [
    "### Optimization Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa18ad",
   "metadata": {},
   "source": [
    "Generalized optimization framework takes as an input the observed data that consists of pre-treatment (X) and post-treatment variables (Y) along with a binary treatment indicator (Z). Further, the framework accepts user defined treatment effect function (f) and selection-bias or confounder-bias function (g). User can also pre-specify the rigidness or strength at which they want the treatment effect and selection-bias to determined by f and g. The optimization objective aims at finding the generative model parameters such that the sum of the distance metric between the joint observed data distribution  and the joint generated data distribution along with the treatment effect constraint and selection bias constraint is minimized. For instance, the distance metric can be Wasserstein distance. The treatment effect constraint forces the condition average treatment effect to be equal to f(X) and the selection bias constraint forces the difference of potential outcome for a treatment under same and opposite treatment to be equal to g(X,Z). In case there is trade-off between minimizing each of the three objectives, the rigidness coefficient is used to prefer one over the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca9b3b5",
   "metadata": {},
   "source": [
    "Let $d$ be a distance metric between two joint distribution and $(X,Y,Z)$ be the observed real data then we want to generate the data $(X',Y',Z')$ that such that\n",
    "$d( (X,Y,Z), (X',Y',Z') ) \\\\ \n",
    "+ \\alpha ( E[Y'(1)-Y'(0)|X'=x'] - f(x') )^2 \\\\ \n",
    "+ \\beta ( E[Y'(z')|X'=x',Z'=z']-E[Y'(z)|X'=x',Z'=1-z'] - g(x',z'))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e9895b",
   "metadata": {},
   "source": [
    "# Example using Credence Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26eb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import tqdm \n",
    "\n",
    "import importlib\n",
    "import autoencoder\n",
    "importlib.reload(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2fa412",
   "metadata": {},
   "source": [
    "## Generating Toy Causal Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451d1d0",
   "metadata": {},
   "source": [
    "* X - pretreatment variable, drawn from standard normal\n",
    "* T - randomly assigned binary treatment with probability 0.5\n",
    "* Y0 - $\\sum_i X_i$\n",
    "* Y1 = Y0$^2$\n",
    "* Y = T Y1 + (1-T) Y0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b47629",
   "metadata": {},
   "source": [
    "generating the toy dataset and plotting Y1 vs Y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(0,1,(2000,5))\n",
    "Y = np.random.normal(np.sum(X,axis=1),1)\n",
    "T = np.random.binomial(1,0.5,size=(X.shape[0],))\n",
    "df = pd.DataFrame(X,columns=['X%d'%(i) for i in range(X.shape[1])])\n",
    "df['Y0'] = Y\n",
    "df['Y1'] = Y**2 + np.random.normal(np.mean(X,axis=1),5)\n",
    "df['T'] = T\n",
    "\n",
    "sns.scatterplot(y='Y0',x='Y1',hue='T',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f848143",
   "metadata": {},
   "source": [
    "# Example 1 (conVAE class) Learning Y0,Y1 | X0...X4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f291ff",
   "metadata": {},
   "source": [
    "Initializing and object of class conVAE to learn conditional distribution of Y1,Y0 | X0,..X4. \n",
    "\n",
    "Note: In this specific case, both Y1 and Y0 are observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb8aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = autoencoder.conVAE(df=df,\n",
    "                       Xnames=['X%d'%(i) for i in range(X.shape[1])],\n",
    "                       Ynames=['Y0','Y1'],\n",
    "                       kld_rigidity=0.5).to('cuda:0')\n",
    "\n",
    "X_tensor = torch.tensor(df[['X%d'%(i) for i in range(X.shape[1])]].values.astype(float)).float().to('cuda:0')\n",
    "Y_tensor = torch.tensor(df[['Y0','Y1']].values.astype(float)).float().to('cuda:0')\n",
    "pi = m.forward(Y_tensor)\n",
    "Y_hat = m.sample(pi, X_tensor)\n",
    "F.mse_loss(Y_hat,Y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd9eb3",
   "metadata": {},
   "source": [
    "Initializing the training and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1, precision=16, limit_train_batches=0.5, max_epochs=100)\n",
    "trainer.fit(m,m.train_loader,m.val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2080667",
   "metadata": {},
   "source": [
    "Comparing the generated data with the true observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.normal(0,1,(2000,5))\n",
    "Y1 = np.random.normal(np.sum(X1,axis=1),1)\n",
    "\n",
    "df1 = pd.DataFrame(X1,columns=['X%d'%(i) for i in range(X1.shape[1])])\n",
    "df1['Y0'] = Y1\n",
    "df1['Y1'] = Y1**2 + np.random.normal(np.mean(X1,axis=1),5)\n",
    "\n",
    "X_tensor = torch.tensor(df1[['X%d'%(i) for i in range(X1.shape[1])]].values.astype(float)).float()\n",
    "Y_tensor = torch.tensor(df1[['Y0','Y1']].values.astype(float)).float()\n",
    "pi = m.forward(Y_tensor)\n",
    "Y_hat = m.sample(pi, X_tensor)\n",
    "F.mse_loss(Y_hat,Y_tensor)\n",
    "\n",
    "sns.set()\n",
    "fig,ax = plt.subplots(ncols=2,figsize=(10,5))\n",
    "ax[0].scatter(y=Y_hat[:,0].detach(),x=Y_hat[:,1].detach())\n",
    "ax[0].set_title('Generated')\n",
    "ax[1].scatter(y=df['Y0'],x=df['Y1'])\n",
    "ax[1].set_title('Observed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875df30",
   "metadata": {},
   "source": [
    "# Example 2 (Credence class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb26f9d",
   "metadata": {},
   "source": [
    "Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a969d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(0,1,(2000,5))\n",
    "Y0 = np.random.normal(np.sum(X,axis=1),1)\n",
    "T = np.random.binomial(1,0.5,size=(X.shape[0],))\n",
    "df = pd.DataFrame(X,columns=['X%d'%(i) for i in range(X.shape[1])])\n",
    "Y1 = Y0**2 + np.random.normal(np.mean(X,axis=1),5)\n",
    "df['T'] = T\n",
    "df['Y'] = T*df['Y1'].values + (1-T)*df['Y0'].values\n",
    "\n",
    "sns.scatterplot(y='Y0',x='Y1',hue='T',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc33848",
   "metadata": {},
   "source": [
    "This is a classic causal example.\n",
    "Importing Credence Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be16f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import credence\n",
    "importlib.reload(credence)\n",
    "df = df.drop(columns=['Y1','Y0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96bb47",
   "metadata": {},
   "source": [
    "Initializing credence object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fa559",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = credence.Credence(data=df, # dataframe \n",
    "                         post_treatment_var=['Y'], # list of post treatment variables\n",
    "                         treatment_var=['T'], # list of treatment variable(s)\n",
    "                         categorical_var=['T'], # list of variables which are categorical\n",
    "                         numerical_var=['X%d'%(i) for i in range(X.shape[1])]+['Y'], # list of variables which are numerical\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8def53",
   "metadata": {},
   "source": [
    "Fitting the credence object with observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = v.fit(effect_rigidity=0,max_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e89745",
   "metadata": {},
   "source": [
    "Sampling using the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb87daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = v.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a942d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
